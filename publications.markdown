---
title: Publications
layout: page
permalink: "/publications/"
---

<!--
If you want to change the style of the table, please look at the publication tag in _sass/_layout.scss.
-->

<!---------------- Publications --------------------->


<!------------------- Journal Articles --------------------->
<div class="publication">
<div class="pub-title"> Journal Articles </div>

<table>
<colgroup>
<col width="25%" />
<col width="75%" />
</colgroup>
<thead>
<tr>
<th class="pub-item" colspan="2"></th>
</tr>
</thead>
<tbody>
<tr>
<td>
    <a href="/assets/research/graphdistnet.png" data-lightbox="" >
      <img style="width: 85%" src="/assets/research/graphdistnet.png">
      </a>
</td>
<td>
    <b>GraphDistNet: A Graph-based Collision-distance Estimator for Gradient-based Trajectory</b><br>
    Yeseung Kim, Jinwoo Kim, Daehyung Park<br>
    <i>IEEE Robotics and Automation Letters (RA-L), Oral presentation in IEEE IROS, 2022</i> <br>
    A graph neural networks (GNN) based collision distance estimator comprised of the message passing and attention mechanism for trajectory optimization. Our method shows high accuracy in complex scenes by using geometric features and calculates massive data fast by the parallelism of GPU.<br>
    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9851942" target="_blank">[PDF]</a> <a href="https://youtu.be/QIBt6AR9KmI" target="_blank">[Video]</a> <a href="https://arxiv.org/abs/2206.01517" target="_blank">[arxiv]</a><br>
</td>
</tr>
</tbody>
</table>


<ol> 
<div class="pub-item"><li>
Howard, T., Stump, E., Fink, J., Arkin, J., Paul, R., <b>Park, D.</b>, Roy, S., Barber, D., Bendell, R., Schmeckpeper, K., Tian, J., Oh, J., Wigness, M., Quang, L., Rothrock, B., Nash, J., Walter, M., Jentsch, F., & Roy, N. "An Intelligence Architecture for Grounded Language Communication with Field Robots", 2022. 
<a href=" http://fieldrobotics.net/Field_Robotics/Volume_2_files/Vol2_17.pdf" target="_blank">[PDF]</a> 
 </li></div>
 
<div class="pub-item"><li>
<b>Daehyung Park*</b>, Jacob Arkin*, Subhro Roy, Matthew R. Walter, Nicholas Roy, Thomas M. Howard, and Rohan Paul. "Multi-Modal Estimation and Communication of Latent Semantic Knowledge for Robust Execution of Robot Instructions", <i>The International Journal of Robotics Research </i>(IJRR), 2020. <a href="https://journals.sagepub.com/eprint/PSW4Z5AXF4AYTSXRN7AI/full" target="_blank">[PDF]</a> <a href="https://www.youtube.com/watch?v=BfCeYsTvaOw&amp;feature=youtu.be" target="_blank">[Video]</a>
</li></div>

<div class="pub-item"><li>
<b>Daehyung Park</b>, Yuuna Hoshi, Harshar P. Mahajan, Ho Keun Kim, Zackory Erickson, Wendy A. Rogers, and Charles C. Kemp. “Active Robot-Assisted Feeding with a General-Purpose Mobile Manipulator: Design, Evaluation, and Lessons Learned”, <i>Robotics and Autonomous Systems</i> (RAS), 2019. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0921889018307061" target="_blank">[PDF]</a> <a href="https://www.youtube.com/watch?v=I5gqtk6Cln8" target="_blank">[Video]</a>
</li></div>

<div class="pub-item"><li>
Ariel Kapusta, Philip Grice, Henry Clever, Yash Chitalia, <b>Daehyung Park</b>, and Charles C. Kemp. “A System for Bedside Assistance that Integrates a Robotic Bed and a Mobile Manipulator,” <i>PLoS ONE</i>, 2019. <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0221854" target="_blank">[PDF]</a> <a href="https://ndownloader.figshare.com/files/18019598" target="_blank">[Video]</a>
</li></div>

<div class="pub-item"><li>
<b>Daehyung Park</b>, Yuuna Hoshi, and Charles C. Kemp. “A Multimodal Anomaly Detector for Robot-Assisted Feeding Using an LSTM-based Variational Autoencoder”, <i>IEEE Robotics and Automation Letters</i> (RA-L), 2018. <a href="http://ieeexplore.ieee.org/document/8279425/" target="_blank">[PDF]</a> <a href="https://youtu.be/ZMAGEQx5Uy8" target="_blank">[Video]</a>
</li></div>

<div class="pub-item"><li>
<b> Daehyung Park</b>, Hokeun Kim, and Charles C. Kemp. “Multimodal Anomaly Detection for Assistive Robots”, <i>Autonomous Robots</i>, 2018. <a href="https://link.springer.com/article/10.1007/s10514-018-9733-6" target="_blank">[PDF]</a>
</li></div>

</ol>

</div>

<!-- <p align="left" style="text-align:left"><span style="font-family:times new roman,serif"><font size="3"><i><br />
</i></font></span></p>
<p align="left" style="text-align:left"><a href="https://youtu.be/gLcPZQnDmkk" target="_blank"></a></p> -->


<!------------------- International Conference Articles --------------------->
<div class="publication">
<div class="pub-title"> International Conference Articles </div>

<table>
<colgroup>
<col width="25%" />
<col width="75%" />
</colgroup>
<thead>
<tr>
<th class="pub-item" colspan="2"></th>
</tr>
</thead>
<tbody>
<tr>
<td>
    <a href="/assets/research/2022_RiTA_framework.png" data-lightbox="" >
      <img style="width: 85%" src="/assets/research/2022_RiTA_framework.png">
      </a>
</td>
<td>
    <b>Natural Language-Guided Navigation using Scene Graph</b><br>
    Dohyun Kim*, Jinwoo Kim*, Minwoo Cho, <b>Daehyung Park</b> (*- authors contributed equally)<br>
    <i>Conference on Robot Intelligence Technology and Applications (RiTA 2022), <b style="color:blue;">Best Student Paper Award</b></i><br>
    A natural language-guided robotic navigation framework that can effectively ground natural language commands in large space. Our framework consists of three modules: a scene-graph generator, a grounding network, and a semantic navigation system. The scene-graph generator incrementally stores the semantic and geometric information of object instances. Then, the proposed scene graph-based grounding network (SGGNet) predicts the desired goal robustly by associating instances in a scene graph with a user command. Finally, the navigation system enables the robot to reach the goal.<br>
    <a href="https://drive.google.com/file/d/1VNGmirCewK2aaGJvAtiUq8iXOzGnGNeY/view?usp=share_link" target="_blank">[PDF]</a> <br>
</td>
</tr>
<tr>
<td>
    <a href="/assets/research/confidence-based_navigation.png" data-lightbox="" >
      <img style="width: 85%" src="/assets/research/confidence-based_navigation.png">
      </a>
</td>
<td>
    <b>Confidence-based Robot Navigation under Sensor Occlusion with Deep Reinforcement Learning</b><br>
    Hyeongyeol Ryu, Minsung Yoon, <b>Daehyung Park</b>, Sung-eui Yoon<br>
    <i>IEEE Int'l. Conf. on Robotics and Automation (ICRA 2022), <b style="color:blue;">Outstanding Navigation Award Finalist</b></i><br>
    A confidence-based navigation method that encourages the robot to explore the uncertain region around the robot maximizing its local confidence. To effectively extract features from the variable size of sensor occlusions, we adopt a point-cloud based representation network. Our method returns a resilient navigation policy via deep reinforcement learning, autonomously avoiding collisions under sensor occlusions while reaching a goal.<br>
    <a href="http://sglab.kaist.ac.kr/CBN-DRL/paper.pdf" target="_blank">[PDF]</a><a href="http://sglab.kaist.ac.kr/CBN-DRL/" target="_blank">[Video]</a> <br>
</td>
</tr>
<tr>
<td>
    <a href="/assets/research/2021_RAL_LTL_BT.gif" data-lightbox="" >
      <img style="width: 85%" src="/assets/research/2021_RAL_LTL_BT.gif">
      </a>
</td>
<td>
    <b>Reactive Task and Motion Planning under Temporal Logic Specifications</b><br>
    Shen Li*, <b>Daehyung Park*</b>, Yoonchang Sung*, Julie Shah, Nicholas Roy  (*- authors contributed equally)<br>
    <i>IEEE Int'l. Conf. on Robotics and Automation (ICRA 2021)</i><br>
    <!--A task-and-motion planning (TAMP) algorithm robust against a human operator’s cooperative or adversarial interventions.  We introduce a dynamically reconfigurable planning methodology with behavior tree-based control strategies toward reactive TAMP, which takes the advantage of previous plans and incremental graph search during temporal logic-based reactive synthesis. Our algorithm also shows efficient recovery functionalities that minimize the number of replanning steps.<br>-->
    <a href="https://drive.google.com/file/d/1cxN0KfKHJLfFXi0iLjhNREyjkqn46viG/view?usp=sharing" target="_blank">[PDF]</a> <a href="https://www.youtube.com/watch?v=lPpMVfBzZH0" target="_blank">[Video]</a> <br>
</td>
</tr>
</tbody>
</table>    
<ol>

<div class="pub-item"><li>
<b>Daehyung Park</b>, Michael Noseworthy, Rohan Paul, Subhro Roy, and Nicholas Roy. "Inferring Task Goals and Constraints using Bayesian Nonparametric Inverse Reinforcement Learning", <i>Conference on Robot Learning (CoRL2019) </i> <a href="https://drive.google.com/open?id=1bswpgVJDXp_9vh55_Gz1cAbylhhjQqhS" target="_blank">[PDF]</a> <a href="https://youtu.be/HgaqH4PWcTI" target="_blank">[Video]</a> <b>Oral presentation, 5% oral acceptance rate</b>
</li></div>

<div class="pub-item"><li>
Michael Noseworthy, Rohan Paul, Subhro Roy, <b>Daehyung Park</b>, and Nicholas Roy "Task-Conditioned Variational Autoencoders for Learning Movement Primitives", <i>Conference on Robot Learning (CoRL2019) </i> <a href="https://drive.google.com/open?id=1HckF-IYaj3zbe2CTSL30VKuHluAtsBBl" target="_blank">[PDF]</a> <i>(27.6% Acceptance Rate)</i>
</li></div>

<div class="pub-item"><li>
Subhro Roy, Michael Noseworthy, Rohan Paul, <b>Daehyung Park</b> and Nicholas Roy. "Leveraging Past References for Robust Language Grounding", <i>Conference on Computational Natural Language Learning</i> (CoNLL 2019) <a href="https://www.aclweb.org/anthology/K19-1040/" target="_blank">[PDF]</a>
</li></div>

<div class="pub-item"><li>
Daniel Nyga, Subhro Roy, Rohan Paul, <b>Daehyung Park</b>, Mihai Pomarlan, Michael Beetz, and Nicholas Roy. "Grounding Robot Plans from Natural Language Instructions with Incomplete World Knowledge", <i>Conference on Robot Learning (CoRL2018)</i> <a href="http://proceedings.mlr.press/v87/nyga18a/nyga18a.pdf" target="_blank">[PDF]</a> <a href="https://youtu.be/uWv-l7XMoB8" target="_blank">[Video]</a> (31% Acceptance Rate)
</li></div>

<div class="pub-item"><li>
Jacob Arkin, Rohan Paul, <b>Daehyung Park</b>, Subhro Roy, Nicholas Roy and Thomas M. Howard. "Real-Time Human-Robot Communication for Manipulation Tasks in Partially Observed Environments", <i>Int'l. Symp. on Experimental Robotics (ISER2018)</i> <a href="https://link.springer.com/chapter/10.1007/978-3-030-33950-0_39" target="_blank">[PDF]</a> <a href="https://youtu.be/JTVJkJavU6g" target="_blank">[Video]</a>
</li></div>

<div class="pub-item"><li>
Henry M. Clever, Ariel Kapusta, <b>Daehyung Park</b>, Zackory Erickson, Yash Chitalia, and Charles C. Kemp. “3D Human Pose Estimation on a Configurable Bed from a Pressure Image”, <i>IEEE/RSJ Int'l. Conf. on Intelligent Robots and Systems (IROS2018)</i> <a href="https://arxiv.org/abs/1804.07873" target="_blank">[PDF]</a>
</li></div>

<div class="pub-item"><li>
<b>Daehyung Park</b>, Hokeun Kim, Yuuna Hoshi, Zackory Erickson, Ariel Kapusta, and Charles C. Kemp. “A Multimodal Execution Monitor with Anomaly Classification for Robot-Assisted Feeding”, <i>IEEE/RSJ Int'l. Conf. on Intelligent Robots and Systems (IROS2017)</i> <a href="https://ieeexplore.ieee.org/abstract/document/8206437" target="_blank">[PDF]</a> <a href="https://youtu.be/KQlVSz3URnA" target="_blank">[Video]</a>
</li></div>

<div class="pub-item"><li>
<b> Daehyung Park</b>, Zackory Erickson, Tapomayukh Bhattacharjee, and Charles C. Kemp. “Multimodal Execution Monitoring for Anomaly Detection During Robot Manipulation”, <i>IEEE Int'l. Conf. on Robotics and Automation, 2016. (ICRA2016)</i> <a href="https://ieeexplore.ieee.org/document/7487160" target="_blank">[PDF]</a> <a href="https://youtu.be/gLcPZQnDmkk" target="_blank">[Video]</a> (34% Acceptance Rate)
</li></div>

<div class="pub-item"><li>
Tapomayukh Bhattacharjee, Ashwin A Shenoi, <b>Daehyung Park</b>, James M. Rehg, and Charles C. Kemp, "Combining Tactile Sensing and Vision for Rapid Haptic Mapping", <i>IEEE/RSJ Int'l. Conf. on Intelligent Robots and Systems (IROS2015)</i> <a href="https://ieeexplore.ieee.org/document/7353522" target="_blank">[PDF]</a>
</li></div>

<div class="pub-item"><li>
Ariel Kapusta, <b>Daehyung Park</b>, and Charles C. Kemp, "Task-Centric Selection of Robot and Environment Initial Configurations to Perform Assistive Tasks", <i>IEEE/RSJ Int'l. Conf. on Intelligent Robots and Systems (IROS2015)</i> <a href="https://ieeexplore.ieee.org/document/7353563" target="_blank">[PDF]</a>
</li></div>

<div class="pub-item"><li>
<b>Daehyung Park</b>, Ariel Kapusta, Jeffrey Hawke, and Charles C. Kemp. “Interleaving Planning and Control for Efficient Haptically-guided Reaching in Unknown Environments”, <i>IEEE-RAS Int'l. Conf. on Humanoid Robots (Humanoids 2014)</i> <a href="https://ieeexplore.ieee.org/document/7041456" target="_blank">[PDF]</a> <a href="https://youtu.be/WHHv3womkYs" target="_blank">[Video]</a>
</li></div>

<div class="pub-item"><li>
<b>Daehyung Park</b>, Ariel Kapusta, Youkeun Kim, James M. Rehg, and Charles C. Kemp. “Learning to Reach into the Unknown: Selecting Initial Conditions When Reaching in Clutter”, <i>IEEE/RSJ Int'l. Conf. on Intelligent Robots and Systems (IROS2014)</i> <a href="https://ieeexplore.ieee.org/document/6942625" target="_blank">[PDF]</a> <a href="https://youtu.be/Gjy-MDEbZUU" target="_blank">[Video]</a>
</li></div>

<div class="pub-item"><li>
Heiko Hoffmann, Peter Pastor, <b>Daehyung Park</b>, and Stefan Schaal. “Biologically-inspired dynamical systems for movement generation: Automatic real-time goal adaptation and obstacle avoidance”, <i>IEEE Int'l. Conf. on Robotics and Automation, 2009. </i> <a href="https://ieeexplore.ieee.org/document/5152423">[PDF]</a>
</li></div>

<div class="pub-item"><li>
<b> Daehyung Park</b>, Heiko Hoffmann, Peter Pastor, and Stefan Schaal. “Movement reproduction and obstacle avoidance with dynamic movement primitives and potential fields”, <i>IEEE-RAS Int'l. Conf. on Humanoid Robots (Humanoids 2008, <b>Oral presentation</b>)</i> <a href="https://ieeexplore.ieee.org/document/4755937">[PDF]</a>
</li></div>

</ol>

</div>




<!------------------- Workshop papers, Abstracts, and Posters --------------------->
<!--
<div class="publication">
<div class="pub-title"> Workshop papers, Abstracts, and Posters </div>

<ol>
</ol>

</div>
-->

<!------------------- Patents --------------------->
<!--
<div class="publication">
<div class="pub-title"> Patents </div>

<ol> 

<div class="pub-item"><li>
<b>D. Park</b>, K. Lee, C. An, and Y. Hong. “Teaching and playback method based on control of redundancy resolution for robot and computer-readable medium controlling the same.” US Patent 12 923 650, Apr. 21, 2011. <a href="https://scienceon.kisti.re.kr/srch/selectPORSrchPatent.do?cn=USP2013108560122&dbt=USPA" target="_blank">[PDF]</a>
</li></div>

<div class="pub-item"><li>
K. Lee, Y. Hong, C. An, and <b>D. Park</b>. “Motor control apparatus and motor control method thereof.” US Patent 13 009 961, Jan. 20, 2011. <a href="https://scienceon.kisti.re.kr/srch/selectPORSrchPatent.do?cn=USP2008087408315">[PDF]</a>
</li></div>

<div class="pub-item"><li>
K. Lee, Y. Hong, C. An, and D. Park. “모터 제어장치 및 모터 제어 방법(MOTOR CONTROL APPARATUS AND CONTROL METHOD THE SAME),” KR Patent App. 1,020,100,006,682, Aug. 2, 2011
</li></div>

<div class="pub-item"><li>
D. Park, K. Lee, C. An, and Y. Hong. “여유자유도 제어를 이용한 로봇의 교시 및 재현 방법 (TEACHING AND PLAYBACK METHOD USING REDUNDANCY RESOLUTION CONTROL FOR MANIPULATOR),” KR Patent App. 1,020,090,099,003, Apr. 22, 2011
</li></div>

</ol>

</div>
-->

---
layout: page
title: Research Areas
permalink: /research/
---


<td markdown="span">
    <a href="/assets/research/research_areas.png" data-lightbox="Research Areas" >
      <img style="width: 1000px" src="/assets/research/research_areas.png">
      </a>
</td>


<table>
<colgroup>
<col width="30%" />
<col width="70%" />
</colgroup>
<thead>
<tr>
<th class="caption">Topic</th>
<th class="caption">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
    <a href="/assets/research/2019_CoRL_CBN_IRL2.png" data-lightbox="corl19_cbnirl" >
      <img style="width: 350px" src="/assets/research/2019_CoRL_CBN_IRL_opt.png">
    </a>
</td>
<td class="description">
<b>Inverse Manipulation Skill Learning</b>
<!--![](//www.youtube.com/watch?v=HgaqH4PWcTI?width=100height=50)-->
<br>
Learning for manipulation is to obtain manipulation skills from a wide range of knowledge sources. We introduce methodologies for learning manipulation constraints and motion parameters from demonstrations. We also target to manipulate not only rigid bodies but also deformable objects via the state-of-the-art Issac Gym simulator. 
<br>
<br>
<b>Keywords</b>: (Inverse) Reinforcement learning, Deformable obejct manipulation, Sim2Real transfer learning
<br>    
<b>Selected paper</b>: Daehyung Park et al. "Inferring Task Goals and Constraints using Bayesian Nonparametric Inverse Reinforcement Learning", CoRL, 2019.
<a href="https://drive.google.com/open?id=1bswpgVJDXp_9vh55_Gz1cAbylhhjQqhS" target="_blank">[PDF]</a><a href="https://youtu.be/HgaqH4PWcTI" target="_blank">[Video]</a>
</td>
</tr>
<tr>
<td markdown="span">
    <a href="/assets/research/2021_RAL_LTL_BT.png" data-lightbox="ral20_ltl_bt" >
      <img style="width: 350px" src="/assets/research/2021_RAL_LTL_BT_opt.png">
      </a>
</td>
<td class="description">
<b>Dynamically Reconfigurable Task-and-Motion Planning</b>
<br> We aim to introduce task-and-motion planning (TAMP) framework that is to solve complex and longer-time horizon of human tasks. To resolve completeness, optimality, and robustness issues, we are working on various task planning and motion planning approaches. We will show a generalizable TAMP framework under human operator’s cooperative or adversarial interventions.
<br>    
<br>
<b>Keywords</b>: Temporal logic, Neuro symbolic planning, Scene graph, Behavior tree
<br>        
<b>Selected paper</b>: Li et al. "Reactive Task and Motion Planning under Temporal Logic Specifications," ICRA, 2021. <a href="https://drive.google.com/file/d/1cxN0KfKHJLfFXi0iLjhNREyjkqn46viG/view?usp=sharing" target="_blank">[PDF]</a><a href="https://youtu.be/lPpMVfBzZH0" target="_blank">[Video]</a>    
</td>
</tr>

<tr>
<td markdown="span">
    <a href="/assets/research/2020_IJRR.png" data-lightbox="ijrr20" >
      <img style="width: 350px" src="/assets/research/2020_IJRR_opt.png">
      </a>
</td>
<td class="description">
<b>Natural Language Understanding for Navigation & Manipulation</b>
<br>Natural language is a convenient means to deliver a user’s high-level instruction. We introduce a language-guided manipulation framework that learns common-sense knowledge from natural language instructions and corresponding motion demonstrations.
<br>
<br>
<b>Keywords</b>: Quadruped robot, Semantic SLAM, Natural language grounding
<br>        
<b>Selected paper</b>: Daehyung Park#, Jacob Arkin# et al. "Multi-Modal Estimation and Communication of Latent Semantic Knowledge for Robust Execution of Robot Instructions", IJRR, 2020. (#- authors contributed equally) 
<a href="https://journals.sagepub.com/eprint/PSW4Z5AXF4AYTSXRN7AI/full" target="_blank">[PDF]</a><a href="https://www.youtube.com/watch?v=BfCeYsTvaOw&amp" target="_blank">[Video]</a>
</td>
</tr>

<tr>
<td markdown="span">
    <a href="/assets/research/2018_CORL.png" data-lightbox="CoRL2018" >
      <img style="width: 350px" src="/assets/research/2018_CORL_opt.png">
      </a>
</td>
<td  class="description">
<b>Machine Common Sense Learning for Robots</b>
<br>Interpreting underspecified instructions re-quires environmental context and background knowledge about how to accomplish complex tasks. We investigate how to incorporate human-like commonsense knowledge for natural language understanding and task executions. You can find related papers as follows,
<br>
<br>
<b>Keywords</b>: 
<br>            
<b>Selected paper</b>: Daniel Nyga et al. "Grounding Robot Plans from Natural Language Instructions with Incomplete World Knowledge", CoRL, 2018.
<a href="http://proceedings.mlr.press/v87/nyga18a/nyga18a.pdf" target="_blank">[PDF]</a><a href="https://youtu.be/uWv-l7XMoB8" target="_blank">[Video]</a>
</td>
</tr>

</tbody>
</table>



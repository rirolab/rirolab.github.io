---
layout: page
title: Research Areas
permalink: /research/topics
main_nav: true
---

<h3>Introduction!</h3>

<div class="video-single-container">
    <iframe src="https://www.youtube.com/embed/U--BgrBPQfI?start=37&end=86&loop=1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen align="middle" seamless></iframe>
</div>
<br>
<br>


<div class="research">

    <!---------------- Topic --------------------->
    <div class="research-section">Generalist Robots in the Wild: Foundation Models for Long-horizon Tasks</div>
    <div class="boundary-line"></div>

    <div class="research-container">
        <br>
        <img src="/assets/equipment/g1.png" alt="Unitree Humanoid Robot G1">
        <br>
        Under construction!!
        <br>
        <br>
        <b>Keywords</b>: Imitation learning, State-space models (SSM), Diffusion policy, Constraint learning
        <br>    
        <b>Selected paper</b>: <a href="https://arxiv.org/abs/2409.14719" target="_blank">[under review]</a> 
    </div>
    <div class="boundary-line"></div>
    <br>

    <!---------------- Topic --------------------->
    <div class="research-section">Interactive Learning Toward In-hand Manipulation of Deformable Objects</div>
    <div class="boundary-line"></div>

    <div class="research-container">
        <br>
        <img src="/assets/research/research_iitp.png" alt="Deformable object manipulation + Inverse constraint learning">
        <br>
        In-hand manipulation of deformable objects offers unprecedented opportunities to resolve various real-world problems, such as binding and taping. This project aims to develop a visuotactile in-hand manipulation that repositions/reorientations deformable objects in hand as we want. Toward this line of research, we propose three research thrusts: 1) a physics-informed reinforcement learning (RL) framework, 2) an interactive RL framework, and 3) Sim2Real transfer learning method.
        <br>
        <br>
        <b>Keywords</b>: (Inverse) Reinforcement learning, Deformable obejct manipulation, Sim2Real transfer learning, 
        <br>    
        <b>Selected paper</b>: <a href="https://proceedings.mlr.press/v100/park20a.html" target="_blank">[CoRL19]</a>, <a href="https://arxiv.org/abs/2306.12357" target="_blank">[RA-L23]</a> 
    </div>
    <div class="boundary-line"></div>
    <br>

    <!---------------- Topic --------------------->
    <div class="research-section">LLM/VLM/LMM-based Task-and-Motion Planning</div>
    <div class="boundary-line"></div>

    <div class="research-container">
        <br>
        <img src="/assets/research/research_TAMP.jpg" alt="Task-and-Motion Planning" >
        <br>
        We aim to introduce task-and-motion planning (TAMP) framework that is to solve complex and longer-time horizon of human tasks. To resolve completeness, optimality, and robustness issues, we are working on various task planning and motion planning approaches. We will show a generalizable TAMP framework under human operator’s cooperative or adversarial interventions.
        <br>    
        <br>
        <b>Keywords</b>: Large language models, Large multimodal models, Semantic perception, Behavior tree
        <br>        
        <b>Selected paper</b>: <a href="https://ieeexplore.ieee.org/abstract/document/9561807" target="_blank">[ICRA21]</a>,  <a href="https://ieeexplore.ieee.org/abstract/document/9851942" target="_blank">[RA-L22]</a>, <a href="https://arxiv.org/abs/2310.04044" target="_blank">[ICRA24]</a>       
    </div>
    <div class="boundary-line"></div>
    <br>

    <!---------------- Topic --------------------->
    <div class="research-section">Language-guided Quadrupedal Robot Navigation & Manipulation</div>
    <div class="boundary-line"></div>

    <div class="research-container">
        <br>
        <img src="/assets/research/research_quad.jpg" alt="Task-and-Motion Planning" >
        <!--img src="/assets/research/research_grounding.png" alt="Commonsense spatial grounding" -->
        <br>
        Natural language is a convenient means to deliver a user’s high-level instruction. We introduce a language-guided manipulation framework that learns common-sense knowledge from natural language instructions and corresponding motion demonstrations. We apply the technologies on various quadrupedal robots like Boston Dynamics Spot!
        <br>
        <br>
        <b>Keywords</b>: Quadruped robot, Semantic SLAM, Natural language grounding, Space grounding
        <br>        
        <b>Selected paper</b>: <a href="https://journals.sagepub.com/eprint/PSW4Z5AXF4AYTSXRN7AI/full" target="_blank">[IJRR20]</a>, <a href="http://fieldrobotics.net/Field_Robotics/Volume_2_files/Vol2_17.pdf" target="_blank">[FR22]</a>, <a href="https://arxiv.org/abs/2402.01183" target="_blank">[AAAI24]</a>
    </div>
    <div class="boundary-line"></div>
    <br>


</div>
